#! @PYTHON3@
import pdb
import argparse 
import sys
from datetime import datetime, timedelta
import requests
import os
import configparser

def get_logs(baseURL, subsystem=None, startDate=None, endDate=None, nLogs=None, dateFormat=None):
    url = baseURL
    if startDate:
        url += f'start_date={startDate}&'
    if endDate:
        url += f'end_date={endDate}&'
    if subsystem:
        url += f'subsystems={subsystem}&'
    if nLogs:
        url += f'n_logs={nLogs}&'
    if dateFormat:
        url += f'date_format={dateFormat}'
    return url 


def get_last_n_minutes_logs(baseURL, subsystem, minutes, endDate=None):
    dateFormat = '%Y-%m-%dT%H:%M:%S'
    if not endDate:
        endDate = datetime.utcnow()
    else:
        endDate = datetime.strptime(endDate, dateFormat)
    startDate = endDate - timedelta(minutes=minutes)
    startDateStr = datetime.strftime(startDate, dateFormat)
    endDateStr = datetime.strftime(endDate, dateFormat)
    url = get_logs(baseURL, subsystem, startDateStr, endDateStr, dateFormat=dateFormat)
    resp = requests.get(url)
    print(url)
    return resp
    
def get_default_config_loc(kroot=False):
    config_loc = os.path.abspath(os.path.dirname(__file__))
    if kroot: 
        config_loc = '/kroot/rel/default/data/'

    config_loc = os.path.join(config_loc, './logger_cfg.ini')
    return config_loc

def print_ouput_json_table(logs):
    excl = ['_id', 'utc_sent' ]
    keys = ([x for x in logs[0].keys() if x not in excl])
    print(', '.join(keys))
    for log in logs:
        # print(log.values())
        row = []
        for key, val in log.items():
            if key in excl: continue
            if key == 'utc_received':
                val = [x for x in val.values()][0]
                row.append(val)
                continue
            if isinstance(val, dict):
                row.append(str(val))
                continue
            if isinstance(val, str):
                row.append(val)
                continue
        print(", ".join(row))
                
        # print(', '.join([str(x) for x in log.values()]))

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Get logs from logger database")
    parser.add_argument('--subsystem', type=str, required=False, default=None,
                         help="subsystem specific logs")
    parser.add_argument('--startDate', type=str, required=False, default=None,
                         help="starting date to retrieve logs")
    parser.add_argument('--endDate', type=str, required=False, default=None,
                         help="ending date to retrieve logs")
    parser.add_argument('--nLogs', type=int, required=False, default=100,
                         help="maximum number of logs to output")
    parser.add_argument('--minutes', type=int, required=False, default=None,
                         help="set to retrieve last n minutes of logs")
    parser.add_argument('--dateFormat', type=str, required=False, default='%Y-%m-%dT%H:%M:%S',
                         help="how the dates are formatted (default is YYYY-mm-ddTHH:MM:SS)")
    parser.add_argument('--kroot', type=bool, required=False, default=False,
                         help="Is this a KROOT run project?")

    config = get_default_config_loc()
    config_parser = configparser.ConfigParser()
    config_parser.read(config)
    config = config_parser['HTTP_LOGGING_SERVER']
    baseurl = config.get('url',  'http://localhost:5000/api/log/get_logs?')
    args = parser.parse_args()

    if args.minutes:
        resp = get_last_n_minutes_logs(baseurl, args.subsystem, args.minutes, args.endDate)
        print(resp.json())
        sys.exit()
    else:
        url = get_logs(baseurl, subsystem=args.subsystem, startDate=args.startDate, endDate=args.endDate, nLogs=args.nLogs, dateFormat=args.dateFormat)
        resp = requests.get(url)
        print(url)
        print_ouput_json_table(resp.json())
        
